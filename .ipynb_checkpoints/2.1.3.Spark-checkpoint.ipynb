{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98c03a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/19 07:40:28 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully from HDFS.\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  1|1467810672|        Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|                                                                                               is upset that he ...|\n",
      "|  2|1467810917|        Mon Apr 06 22:19:...|NO_QUERY|       mattycus|                                                                                               @Kenichan I dived...|\n",
      "|  3|1467811184|        Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|                                                                                               my whole body fee...|\n",
      "|  4|1467811193|        Mon Apr 06 22:19:...|NO_QUERY|         Karoli|                                                                                               @nationwideclass ...|\n",
      "|  5|1467811372|        Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|                                                                                               @Kwesidei not the...|\n",
      "|  6|1467811592|        Mon Apr 06 22:20:...|NO_QUERY|        mybirch|                                                                                                        Need a hug |\n",
      "|  7|1467811594|        Mon Apr 06 22:20:...|NO_QUERY|           coZZ|                                                                                               @LOLTrish hey  lo...|\n",
      "|  8|1467811795|        Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|                                                                                               @Tatiana_K nope t...|\n",
      "|  9|1467812025|        Mon Apr 06 22:20:...|NO_QUERY|        mimismo|                                                                                               @twittera que me ...|\n",
      "| 10|1467812416|        Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|                                                                                               spring break in p...|\n",
      "| 11|1467812579|        Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|                                                                                               I just re-pierced...|\n",
      "| 12|1467812723|        Mon Apr 06 22:20:...|NO_QUERY|           TLeC|                                                                                               @caregiving I cou...|\n",
      "| 13|1467812771|        Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|                                                                                               @octolinz16 It it...|\n",
      "| 14|1467812784|        Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|                                                                                               @smarrison i woul...|\n",
      "| 15|1467812799|        Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|                                                                                               @iamjazzyfizzle I...|\n",
      "| 16|1467812964|        Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|                                                                                               Hollis' death sce...|\n",
      "| 17|1467813137|        Mon Apr 06 22:20:...|NO_QUERY|       armotley|                                                                                               about to file taxes |\n",
      "| 18|1467813579|        Mon Apr 06 22:20:...|NO_QUERY|     starkissed|                                                                                               @LettyA ahh ive a...|\n",
      "| 19|1467813782|        Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|                                                                                               @FakerPattyPattz ...|\n",
      "| 20|1467813985|        Mon Apr 06 22:20:...|NO_QUERY|         quanvu|                                                                                               @alydesigns i was...|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time                          # Built-in, no version.\n",
    "import pandas as pd                  # Version 2.2.1.\n",
    "from datetime import datetime        # Built-in, no version.\n",
    "from pyspark.sql import SparkSession # Version 3.4.2.\n",
    "\n",
    "start_time = time.time()\n",
    "# Initializing Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MoveProjectTweetsToWindows\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Defining paths\n",
    "hdfs_path = \"hdfs:///CA2_S2/ProjectTweets.csv\"\n",
    "local_path = \"/media/sf_VM_Shared/ProjectTweets.csv\"\n",
    "\n",
    "# Reading the CSV file from HDFS\n",
    "df_spark = spark.read.csv(hdfs_path, header=True, inferSchema=True)\n",
    "print(\"File read successfully from HDFS.\")\n",
    "\n",
    "# Showing the Spark DataFrame to ensure it is loaded correctly\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca77f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame converted to Pandas DataFrame successfully.\n",
      "File has been saved successfully into VM_Shared folder!\n"
     ]
    }
   ],
   "source": [
    "# Converting the Spark DataFrame to a Pandas DataFrame\n",
    "df_pandas = df_spark.toPandas()\n",
    "print(\"DataFrame converted to Pandas DataFrame successfully.\")\n",
    "\n",
    "# Save the Pandas DataFrame into the shared VM folder\n",
    "df_pandas.to_csv(local_path, index=False)\n",
    "print(\"File has been saved successfully into VM_Shared folder!\")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b781c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 1 minutes 52 seconds\n"
     ]
    }
   ],
   "source": [
    "execution_time = end_time - start_time\n",
    "# Convert execution time to minutes and seconds\n",
    "minutes = int(execution_time // 60)\n",
    "seconds = int(execution_time % 60)\n",
    "print(f\"Total execution time: {minutes} minutes {seconds} seconds\") # Usually it takes 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2266ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3.Spark.ipynb was last run on: May 19, 2024, 07:42:17\n"
     ]
    }
   ],
   "source": [
    "# Getting current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Formatting the date and time in a readable format:\n",
    "formatted_time = current_time.strftime('%B %d, %Y, %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(f\"2.1.3.Spark.ipynb was last run on: {formatted_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8508700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
