###### Hadoop ######
hdfs dfs -rm -r /CA1_S2
hadoop fs -mkdir /CA1_S2
hadoop fs -put ./people_increased.csv /CA1_S2
hdfs fsck hdfs:///CA1_S2/people_increased.csv -files -blocks -locations
hadoop fs -ls /

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar -mapper ./mapper.py -reducer ./reducer.py -input /CA2_S2/CleanProjectTweets.csv -output /CA2_S2_MapReduceOutput

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar -mapper ./mapperc.py -reducer ./reducerc.py -input /CA2_S2/CleanProjectTweets.csv -output /CA2_S2_tweetsclean

hadoop fs -rm -r /CA2_S2_MapReduceOutput

hadoop fs -chmod -R 777 /CA2_S2/
hadoop fs -rm -r /CA2_S2/CleanProjectTweetsCleaned.csv



####### MySQL #######

mysql -u root -p

show databases;

use BenchTest;

show tables;

delete from usertable;

####### Cassandra #########
# To find out cassandra IP:
hostname -I

--Firing up Cassandra, let it running:
cd /usr/local/cassandra/
bin/cassandra -f


--In a different terminal:
cd /usr/local/cassandra
bin/cqlsh

--See keyspaces:
DESCRIBE KEYSPACES;

--Creating twitterdb
CREATE KEYSPACE twitterdb WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };

cqlsh> use twitterdb;


CREATE TABLE tweets (
    ids text,
    tweet_id text,
    date text,
    flag text,
    user text,
    text text,
    PRIMARY KEY (ids)
);

DESCRIBE table tweets;

COPY twitterdb.tweets (ids, tweet_id, date, flag, user, text) 
FROM '/home/hduser/Desktop/CA2_S2/CleanProjectTweets.csv' 
WITH HEADER = true AND delimiter = ',';

CREATE TABLE tweets(ids text, tweet_id text, date text, flag text, user text, text text, primary key (ids, tweet_id, date, flag, user, text));

COPY tweets FROM '/home/hduser/Desktop/CA2_S2/CleanTweets.csv'  WITH HEADER = TRUE AND DELIMITER = ',';

SELECT * FROM twitter LIMIT 100;

--To delete records:
TRUNCATE usertable;


##### Mongodb #######

mongod --bind_ip 127.0.0.1
--Let this command running in a separate window.

Type below command in a new window:
mongo
show dbs


###### YCSB #######

cd /home/hduser/ycsb-0.17.0
--workloads, to inspect the various workloads
cd workloads

--Uploading Records to MySQL:
./bin/ycsb.sh load jdbc -P ./jdbc-binding/conf/db.properties -P workloads/workloada

--Running workloads a, b, c and g for MySQL:
./bin/ycsb.sh run jdbc -P workloads/workloada -P ./jdbc-binding/conf/db.properties
./bin/ycsb.sh run jdbc -P workloads/workloadb -P ./jdbc-binding/conf/db.properties
./bin/ycsb.sh run jdbc -P workloads/workloadc -P ./jdbc-binding/conf/db.properties
./bin/ycsb.sh run jdbc -P workloads/workloadg -P ./jdbc-binding/conf/db.properties

--Uploading Records to Mongodb:
./bin/ycsb.sh load mongodb -s -P workloads/workloada

--Running workloads a, b, c and g for MongoDB:
./bin/ycsb.sh run mongodb -s -P workloads/workloada
./bin/ycsb.sh run mongodb -s -P workloads/workloadb
./bin/ycsb.sh run mongodb -s -P workloads/workloadc
./bin/ycsb.sh run mongodb -s -P workloads/workloadg

--Uploading Records to Cassandra:
-First create this table:

create keyspace ycsb WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor': 3 };
USE ycsb;
create table usertable (y_id varchar primary key,field0 varchar,field1 varchar,field2 varchar,field3 varchar,field4 varchar,field5 varchar,field6 varchar,field7 varchar,field8 varchar,field9 varchar);

-Run below command to load records
./bin/ycsb.sh load cassandra-cql -p hosts=10.0.2.15,127.0.0.1 -p port=9042 -p debug=true -P workloads/workloada -s

--Running workloads a, b, c and g for MongoDB:

./bin/ycsb.sh run cassandra-cql -p hosts=10.0.2.15,127.0.0.1 -p port=9042 -p debug=true -P workloads/workloada -s
./bin/ycsb.sh run cassandra-cql -p hosts=10.0.2.15,127.0.0.1 -p port=9042 -p debug=true -P workloads/workloadb -s
./bin/ycsb.sh run cassandra-cql -p hosts=10.0.2.15,127.0.0.1 -p port=9042 -p debug=true -P workloads/workloadc -s
./bin/ycsb.sh run cassandra-cql -p hosts=10.0.2.15,127.0.0.1 -p port=9042 -p debug=true -P workloads/workloadg -s
















